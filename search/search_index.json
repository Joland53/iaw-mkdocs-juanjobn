{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Principal"},{"location":"about/","text":"Juan Jos\u00e9 Berbel Najas","title":"Acerca de"},{"location":"about/#juan-jose-berbel-najas","text":"","title":"Juan Jos\u00e9 Berbel Najas"},{"location":"iot/","text":"IoT Dashboard - Sensores, MQTT, Telegraf, InfluxDB y Grafana Descripci\u00f3n En cada aula del instituto vamos a tener un Wemos D1 mini , un sensor de CO2 y un sensor de temperatura/humedad DHT11 que van a ir tomando medidas de forma constante y las van a ir publicando en un topic de un broker MQTT . Podr\u00edamos seguir la siguiente estructura de nombres para los topics del edificio: iescelia/aula<n\u00famero>/temperature iescelia/aula<n\u00famero>/humidity iescelia/aula<n\u00famero>/co2 Por ejemplo para el aula20 tendr\u00edamos los siguientes topics : iescelia/aula20/temperature iescelia/aula20/humidity iescelia/aula20/co2 Tambi\u00e9n existir\u00e1 un agente de Telegraf que estar\u00e1 suscrito a los topics del broker MQTT donde se publican los valores recogidos por los sensores. El agente de Telegraf insertar\u00e1 los valores que recoge del broker MQTT en una base de datos InfluxDB , que es un sistema gestor de bases de datos dise\u00f1ado para almacenar series temporales de datos.Finalmente tendremos un servicio web Grafana que nos permitir\u00e1 visualizar los datos en un panel de control. Sensores Wemos D1 mini Wemos D1 mini es una placa de prototipado que incluye el SoC (System on Chip) ESP8266 que integra un microcontrolador de prop\u00f3sito general de 32 bits y conectividad WiFi. Sensor de temperatura/humedad DHT11 Lectura del sensor de temperatura/humedad DHT11 y publicaci\u00f3n de datos en el broker MQTT Vamos a hacer uso de la librer\u00eda Adafruit MQTT para conectar con el broker MQTT y publicar los datos que vamos obteniendo de los sensores DHT11. Podemos utilizar el siguiente c\u00f3digo de ejemplo: #include \"DHT.h\" #include <ESP8266WiFi.h> #include \"Adafruit_MQTT.h\" #include \"Adafruit_MQTT_Client.h\" #define DHTPIN D4 #define DHTTYPE DHT11 DHT dht(DHTPIN, DHTTYPE); #define WLAN_SSID \"PUT_YOUR_WLAN_SSID_HERE\" #define WLAN_PASS \"PUT_YOUR_WLAN_PASS_HERE\" #define MQTT_SERVER \"PUT_YOUR_MQTT_SERVER_HERE\" #define MQTT_SERVERPORT 1883 #define MQTT_USERNAME \"\" #define MQTT_KEY \"\" #define MQTT_FEED_TEMP \"iescelia/aula22/temperature\" #define MQTT_FEED_HUMI \"iescelia/aula22/humidity\" WiFiClient client; Adafruit_MQTT_Client mqtt(&client, MQTT_SERVER, MQTT_SERVERPORT, MQTT_USERNAME, MQTT_USERNAME, MQTT_KEY); Adafruit_MQTT_Publish temperatureFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_TEMP); Adafruit_MQTT_Publish humidityFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_HUMI); //---------------------------------------------- void connectWiFi(); //---------------------------------------------- void setup() { Serial.begin(115200); Serial.println(\"IoT demo\"); dht.begin(); connectWiFi(); connectMQTT(); } //---------------------------------------------- void loop() { delay(2000); float h = dht.readHumidity(); float t = dht.readTemperature(); if (isnan(h) || isnan(t)) { Serial.println(\"Failed to read from DHT sensor!\"); return; } Serial.print(\"Humidity: \"); Serial.print(h); Serial.print(\" %\\t\"); Serial.print(\"Temperature: \"); Serial.print(t); Serial.println(\" *C \"); temperatureFeed.publish(t); humidityFeed.publish(h); } //---------------------------------------------- void connectWiFi() { WiFi.begin(WLAN_SSID, WLAN_PASS); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } Serial.println(\"WiFi connected\"); Serial.println(\"IP address: \"); Serial.println(WiFi.localIP()); } //---------------------------------------------- void connectMQTT() { if (mqtt.connected()) return; Serial.print(\"Connecting to MQTT... \"); while (mqtt.connect() != 0) { Serial.println(\"Error. Retrying MQTT connection in 5 seconds...\"); mqtt.disconnect(); delay(5000); } } Sensor de CO2 Lectura del sensor de CO2 y publicaci\u00f3n de datos en el broker MQTT Vamos a hacer uso de la librer\u00eda Adafruit MQTT para conectar con el broker MQTT y publicar los datos que vamos obteniendo de los sensores CCS811. Podemos utilizar el siguiente c\u00f3digo de ejemplo: #include <ESP8266WiFi.h> #include <Adafruit_Sensor.h> #include \"Adafruit_MQTT.h\" #include \"Adafruit_MQTT_Client.h\" #include <CCS811.h> // WiFi configuration #define WLAN_SSID \"PUT_YOUR_WLAN_SSID_HERE\" #define WLAN_PASS \"PUT_YOUR_WLAN_PASS_HERE\" // MQTT configuration #define MQTT_SERVER \"PUT_YOUR_MQTT_SERVER_HERE\" #define MQTT_SERVERPORT 1883 #define MQTT_USERNAME \"\" #define MQTT_KEY \"\" #define MQTT_FEED_CO2 \"iescelia/aula22/co2\" #define MQTT_FEED_TVOC \"iescelia/aula22/tvoc\" // WiFi connection WiFiClient client; // MQTT connection Adafruit_MQTT_Client mqtt(&client, MQTT_SERVER, MQTT_SERVERPORT, MQTT_USERNAME, MQTT_USERNAME, MQTT_KEY); // Feed to publish CO2 Adafruit_MQTT_Publish co2Feed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_CO2); // Feed to publish TVOC Adafruit_MQTT_Publish tvocFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_TVOC); CCS811 sensor; //---------------------------------------------- void connectWiFi(); void connectMQTT(); void initSensor(); //---------------------------------------------- void setup() { Serial.begin(115200); Serial.println(\"CO2 IES Celia\"); connectWiFi(); connectMQTT(); initSensor(); } //---------------------------------------------- void loop() { // Wait a few seconds between measurements. delay(1000); if(sensor.checkDataReady() == false){ Serial.println(\"Data is not ready!\"); return; } float co2 = sensor.getCO2PPM(); float tvoc = sensor.getTVOCPPB(); Serial.print(\"CO2: \"); Serial.print(co2); Serial.print(\" ppm\\t\"); Serial.print(\"TVOC: \"); Serial.print(tvoc); Serial.println(\" ppb\"); co2Feed.publish(co2); tvocFeed.publish(tvoc); } //---------------------------------------------- void initSensor() { // Wait for the chip to be initialized completely while(sensor.begin() != 0){ Serial.println(\"Failed to init chip, please check if the chip connection is fine\"); delay(1000); } // eClosed Idle (Measurements are disabled in this mode) // eCycle_1s Constant power mode, IAQ measurement every second // eCycle_10s Pulse heating mode IAQ measurement every 10 seconds // eCycle_60s Low power pulse heating mode IAQ measurement every 60 seconds // eCycle_250ms Constant power mode, sensor measurement every 250ms sensor.setMeasCycle(sensor.eCycle_250ms); } //---------------------------------------------- void connectWiFi() { WiFi.begin(WLAN_SSID, WLAN_PASS); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } Serial.println(\"WiFi connected\"); Serial.println(\"IP address: \"); Serial.println(WiFi.localIP()); } //---------------------------------------------- void connectMQTT() { if (mqtt.connected()) return; Serial.print(\"Connecting to MQTT... \"); while (mqtt.connect() != 0) { Serial.println(\"Error. Retrying MQTT connection in 5 seconds...\"); mqtt.disconnect(); delay(5000); } } MQTT Broker MQTT (MQ Telemetry Transport) es un protocolo de mensajer\u00eda est\u00e1ndar utilizado en las aplicaciones de Internet de las cosas (IoT). Se trata de un protocolo de mensajer\u00eda muy ligero basado en el patr\u00f3n publish/subscribe, donde los mensajes son publicados en un topic de un MQTT Broker que se encargar\u00e1 de distribuirlos a todos los suscriptores que se hayan suscrito a dicho topic. Eclipse Mosquitto ser\u00e1 el MQTT Broker que vamos a utilizar en este proyecto. Descripci\u00f3n del servicio en docker-compose.yml docker-compose.yml mosquitto: image: eclipse-mosquitto:2 ports: - 1883:1883 volumes: - ./mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf - mosquitto_data:/mosquitto/data - mosquitto_log:/mosquitto/log Archivo de configuraci\u00f3n mosquitto.conf Este archivo estar\u00e1 almacenado en el directorio ./mosquitto/mosquitto.conf de nuestra m\u00e1quina local. Como vamos a utilizar la versi\u00f3n 2 del broker MQTT eclipse-mosquitto vamos a necesitar crear un archivo de configuraci\u00f3n llamado mosquitto.conf que incluya las siguientes opciones de configuraci\u00f3n. mosquitto.conf listener 1883 allow_anonymous true En este punto, el contenido de nuestro directorio de trabajo debe tener los siguientes archivos. . \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 mosquitto \u2514\u2500\u2500 mosquitto.conf Cliente MQTT para publicar en un topic (publish) En esta secci\u00f3n vamos a explicar c\u00f3mo podemos hacer uso de un cliente MQTT para publicar mensajes de prueba en el broker MQTT que acabamos de crear. Esta comprobaci\u00f3n deber\u00edamos realizarla antes de empezar a trabajar directamente con los sensores sobre el broker MQTT. Una vez que hayamos comprobado que podemos publicar y suscribirnos a los mensajes del broker con este cliente, ya podr\u00edamos realizar el siguiente paso para publicar mensajes con los sensores y recibirlos con el agente de Telegraf. Ejemplo: En este ejemplo vamos a publicar el valor 30 en el topic iescelia/aula22/co2 del broker MQTT test.mosquitto.org. Este broker es de prueba, por lo tanto, tendremos que cambiar este broker por la direcci\u00f3n IP de nuestro broker MQTT. docker run --init -it --rm efrecon/mqtt-client pub -h test.mosquitto.org -p 1883 -t \"iescelia/aula22/co2\" -m 30 Cliente MQTT para suscribirse a un topic (subscribe) Podemos hacer uso de un cliente MQTT para suscribirnos a los mensajes que se publican en un topic espec\u00edfico del broker MQTT. Esta comprobaci\u00f3n deber\u00edamos realizarla antes de empezar a trabajar directamente con los sensores sobre el broker MQTT. Una vez que hayamos comprobado que podemos publicar y suscribirnos a los mensajes del broker con este cliente, ya podr\u00edamos realizar el siguiente paso para publicar mensajes con los sensores y recibirlos con el agente de Telegraf. Ejemplo: En este ejemplo nos vamos a suscribir al topic iescelia/ del broker MQTT test.mosquitto.org. Con el wildcard estamos indicando que queremos suscribirnos a todos los topics que existan dentro de iescelia/, es decir, todos los mensajes que se publiquen en cada una de las aulas. Tenga en cuenta que tendr\u00e1 que cambiar el broker test.mosquitto.org por la direcci\u00f3n IP de nuestro broker MQTT. docker run --init -it --rm efrecon/mqtt-client sub -h test.mosquitto.org -t \"iescelia/#\" Telegraf Telegraf es un agente que nos permite recopilar y reportar m\u00e9tricas. Las m\u00e9tricas recogidas se pueden enviar a almacenes de datos, colas de mensajes o servicios como: InfluxDB, Graphite, OpenTSDB, Datadog, Kafka, MQTT, NSQ, entre otros. Descripci\u00f3n del servicio en docker-compose.yml docker-compose.yml telegraf: image: telegraf volumes: - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf depends_on: - influxdb Creaci\u00f3n del archivo de configuraci\u00f3n telegraf.conf En primer lugar tenemos que crear el archivo de configuraci\u00f3n telegraf.conf en nuestra m\u00e1quina local. Para crear el archivo de configuraci\u00f3n haremos uso del comando telegram config dentro del contenedor de Telegraf. docker run --rm telegraf telegraf config > telegraf.conf Una vez que hemos creado el archivo telegraf.conf lo movemos al directorio telegraf de nuestro proyecto. El contenido de nuestro directorio de trabajo debe tener los siguientes archivos. . \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 mosquitto \u2502 \u2514\u2500\u2500 mosquitto.conf \u2514\u2500\u2500 telegraf \u2514\u2500\u2500 telegraf.conf Configuraci\u00f3n del archivo telegraf.conf para suscribirnos a un topic MQTT Tendremos que buscar la secci\u00f3n inputs.mqtt_consumer dentro del archivo telegraf.conf y configurar los siguientes valores: servers topics data_format Existen m\u00e1s directivas de configuraci\u00f3n (qos, client_id, username, password, etc.), pero en este proyecto s\u00f3lo vamos a utilizar los valores que hemos indicado anteriormente. servers En esta directiva de configuraci\u00f3n indicamos la URL del broker MQTT al que queremos conectarnos. En nuestro caso pondremos el nombre del servicio mosquitto que es como lo hemos definido en nuestro archivo docker-compose.yml. topics En esta directiva indicamos los topics a los que queremos suscribirnos. En nuestro caso pondremos el topic iescelia/#. El car\u00e1cter # al final del topic indica que nos vamos a suscribir a cualquier topic que exista despu\u00e9s de la cadena iescelia/. data_format En esta directiva indicamos c\u00f3mo es el formato de los datos que vamos a recibir por MQTT. Telegraf contiene muchos plugins de prop\u00f3sito general que permiten parsear datos de entrada para convertirlos en el modelo de datos de m\u00e9tricas que utiliza InfluxDB. Formato: Value El formato value permite convertir valores simples en m\u00e9tricas de Telegraf. Es necesario indicar el tipo de dato al que queremos convertir el valor le\u00eddo, utilizando la opci\u00f3n de configuraci\u00f3n data_type. Los tipos de datos disponibles son: integer float o long string boolean Ejemplo de configuraci\u00f3n de la secci\u00f3n inputs.mqtt_consumer Si los mensajes que vamos a recibir por MQTT s\u00f3lo contienen valores num\u00e9ricos de tipo real que representan valores de temperatura, tendr\u00edamos que indicar: data_format = \"value\" y data_type = \"float\". Una posible configuraci\u00f3n para la secci\u00f3n inputs.mqtt_consumer del archivo telegraf.conf podr\u00eda ser la siguiente. [[inputs.mqtt_consumer]] servers = [\"tcp://mosquitto:1883\"] topics = [ \"iescelia/#\" ] data_format = \"value\" data_type = \"float\" Formato: InfluxDB Line Protocol El formato influx no necesita ninguna configuraci\u00f3n adicional. Los valores que se reciben son parseados autom\u00e1ticamente a m\u00e9tricas de Telegraf. Si utilizamos data_format = \"influx\" los mensajes de entrada tienen que cumplir la sintaxis del protocolo InfluxDB line protocol. A continuaci\u00f3n se muestra un ejemplo de un mensaje con las sintaxis de InfluxDB line protocol. weather,location=us-midwest temperature=82 1465839830100400200 | -------------------- -------------- | | | | | | | | | +-----------+--------+-+---------+-+---------+ |measurement|,tag_set| |field_set| |timestamp| +-----------+--------+-+---------+-+---------+ El mensaje se compone de cuatro componentes: measurement: Indica la estructura de datos donde vamos a almacenar los valores en InfluxDB. tag_set: Es opcional. Son tags opcionales asociados al dato. Van detr\u00e1s de una coma despu\u00e9s del nombre de la measurement, sin espacios en blanco. field_set: Son los datos. Aparecen despu\u00e9s de un espacio en blanco despu\u00e9s de la meausrement. Podemos indicar varios datos separados por comas. timestamp: Es opcional. Es una marca de tiempo en Unix con precisi\u00f3n de nanosegundos. Ejemplos de mensajes v\u00e1lidos con la sintaxis del protocolo InfluxDB line protocol weather,location=us-midwest temperature=82 1465839830100400200 weather temperature=82 1465839830100400200 weather temperature=82 weather temperature=82,humidity=71 1465839830100400200 weather temperature=82,humidity=71 Ejemplo de configuraci\u00f3n de la secci\u00f3n inputs.mqtt_consumer Una posible configuraci\u00f3n para la secci\u00f3n inputs.mqtt_consumer del archivo telegraf.conf podr\u00eda ser la siguiente. [[inputs.mqtt_consumer]] servers = [\"tcp://mosquitto:1883\"] topics = [ \"iescelia/#\" ] data_format = \"influx\" Configuraci\u00f3n del archivo telegraf.conf para almacenar los datos en InfluxDB (outputs.influxdb) Tendremos que buscar la secci\u00f3n outputs.influxdb dentro del archivo telegraf.conf y configurar los siguientes valores: urls database skip_database_creation username password Existen m\u00e1s directivas de configuraci\u00f3n, pero en este proyecto s\u00f3lo vamos a utilizar los valores que hemos indicado anteriormente. urls En esta directiva de configuraci\u00f3n indicamos la URL de la instancia de InfluxDB donde vamos a almacenar los datos. En nuestro caso pondremos influxdb que es el nombre que le hemos puesto al servicio en el archivo docker-compose.yml database En esta directiva indicamos el nombre de la base de datos donde vamos a almacenar las m\u00e9tricas. skip_database_creation Permite evitar la creaci\u00f3n de bases de datos en InfluxDB cuando est\u00e1 configurada como true. Se recomienda configurarla a true cuando estemos trabajando con usuarios que no tienen permisos para crear bases de datos o cuando la base de datos ya exista. username y password En esta directiva configuramos los par\u00e1metros de autenticaci\u00f3n para conectarnos a InfluxDB. Ejemplo de configuraci\u00f3n de la secci\u00f3n outputs.mqtt_consumer Una posible configuraci\u00f3n de la secci\u00f3n outputs.influxdb podr\u00eda ser la siguiente: [[outputs.influxdb]] urls = [\"http://influxdb:8086\"] database = \"iescelia_db\" skip_database_creation = true username = \"root\" password = \"root\" InfluxDB InfluxDB es un sistema gestor de bases de datos dise\u00f1ado para almacenar bases de datos de series temporales (TSBD - Time Series Databases). Estas bases de datos se suelen utilizar en aplicaciones de monitorizaci\u00f3n, donde es necesario almacenar y analizar grandes cantidades de datos con marcas de tiempo, como pueden ser datos de uso de cpu, uso memoria, datos de sensores de IoT, etc. Descripci\u00f3n del servicio en docker-compose.yml docker-compose.yml influxdb: image: influxdb ports: - 8086:8086 volumes: - influxdb_data:/var/lib/influxdb environment: - INFLUXDB_DB=iescelia_db - INFLUXDB_ADMIN_USER=root - INFLUXDB_ADMIN_PASSWORD=root - INFLUXDB_HTTP_AUTH_ENABLED=true Conectar a InfluxDB desde un terminal Podemos conectarnos al contenedor de InfluxDB desde un terminal para comprobar si los datos que estamos recogiendo de los sensores se est\u00e1n insertando de forma correcta en la base de datos. En primer lugar necesitamos obtener el ID del contenedor que se est\u00e1 ejecutando con InfluxDB. Para obtener el listado de todos los contenedores que est\u00e1n en ejecuci\u00f3n podemos ejecutar el siguiente comando: docker ps Ahora s\u00f3lo tenemos que buscar el ID del contenedor con InfluxDB entre la lista de contenedores. En el ejemplo que se muestra a continuaci\u00f3n ser\u00eda el valor 27b06d552719. CONTAINER ID IMAGE COMMAND ... 27b06d552719 influxdb \"/entrypoint.sh infl\u2026\" ... ... Una vez que tenemos el ID del contenedor de InfluxDB, creamos un nuevo proceso con el comando /bin/bash dentro del contenedor para obtener un terminal que nos permita interactuar con el contenedor. docker exec -it 27b06d552719 /bin/bash Una vez que tenemos un terminal en el contenedor de InfluxDB, utilizamos el cliente influx para conectarnos al sistema gestor de bases de datos con el usuario y contrase\u00f1a que hemos creado en el archivo docker-compose.yml. influx -username root -password root Despu\u00e9s de autenticarnos, tendremos acceso al shell de InfluxDB donde podemos interaccionar con la base de datos con sentencias InfluxQL (Influx Query Language), que tienen una sintaxis muy similar a SQL. Grafana Grafana es un servicio web que nos permite visualizar en un panel de control los datos almacenados en InfluxDB y otros sistemas gestores de bases de datos de series temporales. Descripci\u00f3n del servicio en docker-compose.yml docker-compose.yml grafana: image: grafana/grafana:7.4.0 ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana depends_on: - influxdb Configuraci\u00f3n de un data source Grafana permite utilizar diferentes data sources, en nuestro proyecto utilizaremos InfluxDB pero tambi\u00e9n es posible utilizar AWS CloudWatch, Elasticsearch, MySQL o PostgreSQl entre otros. Configuraci\u00f3n de forma manual Antes de crear un dashboard es necesario crear un data source. S\u00f3lo los usuarios que tengan rol de administrador podr\u00e1n crear un data source. Para crear un data source debe seguir los siguientes pasos. Accede al menu lateral haciendo clien en el icono de Grafana del encabezado superior. Accede a la secci\u00f3n \"Data Sources\". A\u00f1ada un nuevo data source. Seleccione InfluxDB en el desplegable donde se indica el tipo de data source. Configure los par\u00e1metros url, database, user y password de su servicio InfluxDB. En la documentaci\u00f3n oficial puede encontrar m\u00e1s informaci\u00f3n sobre c\u00f3mo utilizar InfluxDB con Grafana. Configuraci\u00f3n con aprovisionamiento autom\u00e1tico Es posible configurar Grafana para que utilize un archivo de configuraci\u00f3n de forma autom\u00e1tica para evitar tener que realizar la configuraci\u00f3n de forma manual. En nuestro proyecto, vamos a crear un archivo con el nombre datasource.yml dentro de la siguiente estructura de directorios. \u251c\u2500\u2500 grafana-provisioning \u2502 \u2514\u2500\u2500 datasources \u2502 \u2514\u2500\u2500 datasource.yml` El contenido del archivo datasource.yml ser\u00e1 el siguiente. apiVersion: 1 datasources: - name: InfluxDB type: influxdb access: proxy database: iescelia_db user: root password: root url: http://influxdb:8086 isDefault: true editable: true Para que el aprovisionamiento se realice forma correcta, tenemos que definir un nuevo volumen en el servicio de Grafana en el archivo docker-compose.yml. docker-compose.yml grafana: image: grafana/grafana:7.4.0 ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana - ./grafana-provisioning/:/etc/grafana/provisioning depends_on: - influxdb Configuraci\u00f3n de un dashboard Configuraci\u00f3n con aprovisionamiento autom\u00e1tico Es posible configurar Grafana para que utilize un archivo de configuraci\u00f3n de forma autom\u00e1tica para evitar tener que realizar la configuraci\u00f3n del dashboard de forma manual. En nuestro proyecto, vamos a crear los archivos dashboard.yml y CO2Dashboard.json dentro de la siguiente estructura de directorios. \u251c\u2500\u2500 grafana-provisioning \u2502 \u251c\u2500\u2500 dashboards \u2502 \u2502 \u251c\u2500\u2500 CO2Dashboard.json \u2502 \u2502 \u2514\u2500\u2500 dashboard.yml \u2502 \u2514\u2500\u2500 datasources \u2502 \u2514\u2500\u2500 datasource.yml El contenido del archivo dashboard.yml ser\u00e1 el siguiente. apiVersion: 1 providers: - name: InfluxDB folder: '' type: file disableDeletion: false editable: true options: path: /etc/grafana/provisioning/dashboards Un dashboard de Grafana se representa por un objeto JSON, que almacena todos los metadatos del dashboard. Estos metadatos incluyen propiedades de los paneles, variables, etc. El archivo CO2Dashboard.json contiene los metadatos del los paneles que hemos creado para el dashboard de este proyecto. A continuaci\u00f3n se muestra una imagen del dashboard almacenado en el archivo CO2Dashboard.json.","title":"Practica IoT"},{"location":"iot/#iot-dashboard-sensores-mqtt-telegraf-influxdb-y-grafana","text":"","title":"IoT Dashboard - Sensores, MQTT, Telegraf, InfluxDB y Grafana"},{"location":"iot/#descripcion","text":"En cada aula del instituto vamos a tener un Wemos D1 mini , un sensor de CO2 y un sensor de temperatura/humedad DHT11 que van a ir tomando medidas de forma constante y las van a ir publicando en un topic de un broker MQTT . Podr\u00edamos seguir la siguiente estructura de nombres para los topics del edificio: iescelia/aula<n\u00famero>/temperature iescelia/aula<n\u00famero>/humidity iescelia/aula<n\u00famero>/co2 Por ejemplo para el aula20 tendr\u00edamos los siguientes topics : iescelia/aula20/temperature iescelia/aula20/humidity iescelia/aula20/co2 Tambi\u00e9n existir\u00e1 un agente de Telegraf que estar\u00e1 suscrito a los topics del broker MQTT donde se publican los valores recogidos por los sensores. El agente de Telegraf insertar\u00e1 los valores que recoge del broker MQTT en una base de datos InfluxDB , que es un sistema gestor de bases de datos dise\u00f1ado para almacenar series temporales de datos.Finalmente tendremos un servicio web Grafana que nos permitir\u00e1 visualizar los datos en un panel de control.","title":"Descripci\u00f3n"},{"location":"iot/#sensores","text":"","title":"Sensores"},{"location":"iot/#wemos-d1-mini","text":"Wemos D1 mini es una placa de prototipado que incluye el SoC (System on Chip) ESP8266 que integra un microcontrolador de prop\u00f3sito general de 32 bits y conectividad WiFi.","title":"Wemos D1 mini"},{"location":"iot/#sensor-de-temperaturahumedad-dht11","text":"","title":"Sensor de temperatura/humedad DHT11"},{"location":"iot/#lectura-del-sensor-de-temperaturahumedad-dht11-y-publicacion-de-datos-en-el-broker-mqtt","text":"Vamos a hacer uso de la librer\u00eda Adafruit MQTT para conectar con el broker MQTT y publicar los datos que vamos obteniendo de los sensores DHT11. Podemos utilizar el siguiente c\u00f3digo de ejemplo: #include \"DHT.h\" #include <ESP8266WiFi.h> #include \"Adafruit_MQTT.h\" #include \"Adafruit_MQTT_Client.h\" #define DHTPIN D4 #define DHTTYPE DHT11 DHT dht(DHTPIN, DHTTYPE); #define WLAN_SSID \"PUT_YOUR_WLAN_SSID_HERE\" #define WLAN_PASS \"PUT_YOUR_WLAN_PASS_HERE\" #define MQTT_SERVER \"PUT_YOUR_MQTT_SERVER_HERE\" #define MQTT_SERVERPORT 1883 #define MQTT_USERNAME \"\" #define MQTT_KEY \"\" #define MQTT_FEED_TEMP \"iescelia/aula22/temperature\" #define MQTT_FEED_HUMI \"iescelia/aula22/humidity\" WiFiClient client; Adafruit_MQTT_Client mqtt(&client, MQTT_SERVER, MQTT_SERVERPORT, MQTT_USERNAME, MQTT_USERNAME, MQTT_KEY); Adafruit_MQTT_Publish temperatureFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_TEMP); Adafruit_MQTT_Publish humidityFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_HUMI); //---------------------------------------------- void connectWiFi(); //---------------------------------------------- void setup() { Serial.begin(115200); Serial.println(\"IoT demo\"); dht.begin(); connectWiFi(); connectMQTT(); } //---------------------------------------------- void loop() { delay(2000); float h = dht.readHumidity(); float t = dht.readTemperature(); if (isnan(h) || isnan(t)) { Serial.println(\"Failed to read from DHT sensor!\"); return; } Serial.print(\"Humidity: \"); Serial.print(h); Serial.print(\" %\\t\"); Serial.print(\"Temperature: \"); Serial.print(t); Serial.println(\" *C \"); temperatureFeed.publish(t); humidityFeed.publish(h); } //---------------------------------------------- void connectWiFi() { WiFi.begin(WLAN_SSID, WLAN_PASS); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } Serial.println(\"WiFi connected\"); Serial.println(\"IP address: \"); Serial.println(WiFi.localIP()); } //---------------------------------------------- void connectMQTT() { if (mqtt.connected()) return; Serial.print(\"Connecting to MQTT... \"); while (mqtt.connect() != 0) { Serial.println(\"Error. Retrying MQTT connection in 5 seconds...\"); mqtt.disconnect(); delay(5000); } }","title":"Lectura del sensor de temperatura/humedad DHT11 y publicaci\u00f3n de datos en el broker MQTT"},{"location":"iot/#sensor-de-co2","text":"","title":"Sensor de CO2"},{"location":"iot/#lectura-del-sensor-de-co2-y-publicacion-de-datos-en-el-broker-mqtt","text":"Vamos a hacer uso de la librer\u00eda Adafruit MQTT para conectar con el broker MQTT y publicar los datos que vamos obteniendo de los sensores CCS811. Podemos utilizar el siguiente c\u00f3digo de ejemplo: #include <ESP8266WiFi.h> #include <Adafruit_Sensor.h> #include \"Adafruit_MQTT.h\" #include \"Adafruit_MQTT_Client.h\" #include <CCS811.h> // WiFi configuration #define WLAN_SSID \"PUT_YOUR_WLAN_SSID_HERE\" #define WLAN_PASS \"PUT_YOUR_WLAN_PASS_HERE\" // MQTT configuration #define MQTT_SERVER \"PUT_YOUR_MQTT_SERVER_HERE\" #define MQTT_SERVERPORT 1883 #define MQTT_USERNAME \"\" #define MQTT_KEY \"\" #define MQTT_FEED_CO2 \"iescelia/aula22/co2\" #define MQTT_FEED_TVOC \"iescelia/aula22/tvoc\" // WiFi connection WiFiClient client; // MQTT connection Adafruit_MQTT_Client mqtt(&client, MQTT_SERVER, MQTT_SERVERPORT, MQTT_USERNAME, MQTT_USERNAME, MQTT_KEY); // Feed to publish CO2 Adafruit_MQTT_Publish co2Feed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_CO2); // Feed to publish TVOC Adafruit_MQTT_Publish tvocFeed = Adafruit_MQTT_Publish(&mqtt, MQTT_FEED_TVOC); CCS811 sensor; //---------------------------------------------- void connectWiFi(); void connectMQTT(); void initSensor(); //---------------------------------------------- void setup() { Serial.begin(115200); Serial.println(\"CO2 IES Celia\"); connectWiFi(); connectMQTT(); initSensor(); } //---------------------------------------------- void loop() { // Wait a few seconds between measurements. delay(1000); if(sensor.checkDataReady() == false){ Serial.println(\"Data is not ready!\"); return; } float co2 = sensor.getCO2PPM(); float tvoc = sensor.getTVOCPPB(); Serial.print(\"CO2: \"); Serial.print(co2); Serial.print(\" ppm\\t\"); Serial.print(\"TVOC: \"); Serial.print(tvoc); Serial.println(\" ppb\"); co2Feed.publish(co2); tvocFeed.publish(tvoc); } //---------------------------------------------- void initSensor() { // Wait for the chip to be initialized completely while(sensor.begin() != 0){ Serial.println(\"Failed to init chip, please check if the chip connection is fine\"); delay(1000); } // eClosed Idle (Measurements are disabled in this mode) // eCycle_1s Constant power mode, IAQ measurement every second // eCycle_10s Pulse heating mode IAQ measurement every 10 seconds // eCycle_60s Low power pulse heating mode IAQ measurement every 60 seconds // eCycle_250ms Constant power mode, sensor measurement every 250ms sensor.setMeasCycle(sensor.eCycle_250ms); } //---------------------------------------------- void connectWiFi() { WiFi.begin(WLAN_SSID, WLAN_PASS); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } Serial.println(\"WiFi connected\"); Serial.println(\"IP address: \"); Serial.println(WiFi.localIP()); } //---------------------------------------------- void connectMQTT() { if (mqtt.connected()) return; Serial.print(\"Connecting to MQTT... \"); while (mqtt.connect() != 0) { Serial.println(\"Error. Retrying MQTT connection in 5 seconds...\"); mqtt.disconnect(); delay(5000); } }","title":"Lectura del sensor de CO2 y publicaci\u00f3n de datos en el broker MQTT"},{"location":"iot/#mqtt-broker","text":"MQTT (MQ Telemetry Transport) es un protocolo de mensajer\u00eda est\u00e1ndar utilizado en las aplicaciones de Internet de las cosas (IoT). Se trata de un protocolo de mensajer\u00eda muy ligero basado en el patr\u00f3n publish/subscribe, donde los mensajes son publicados en un topic de un MQTT Broker que se encargar\u00e1 de distribuirlos a todos los suscriptores que se hayan suscrito a dicho topic. Eclipse Mosquitto ser\u00e1 el MQTT Broker que vamos a utilizar en este proyecto.","title":"MQTT Broker"},{"location":"iot/#descripcion-del-servicio-en-docker-composeyml","text":"docker-compose.yml mosquitto: image: eclipse-mosquitto:2 ports: - 1883:1883 volumes: - ./mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf - mosquitto_data:/mosquitto/data - mosquitto_log:/mosquitto/log","title":"Descripci\u00f3n del servicio en docker-compose.yml"},{"location":"iot/#archivo-de-configuracion-mosquittoconf","text":"Este archivo estar\u00e1 almacenado en el directorio ./mosquitto/mosquitto.conf de nuestra m\u00e1quina local. Como vamos a utilizar la versi\u00f3n 2 del broker MQTT eclipse-mosquitto vamos a necesitar crear un archivo de configuraci\u00f3n llamado mosquitto.conf que incluya las siguientes opciones de configuraci\u00f3n. mosquitto.conf listener 1883 allow_anonymous true En este punto, el contenido de nuestro directorio de trabajo debe tener los siguientes archivos. . \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 mosquitto \u2514\u2500\u2500 mosquitto.conf","title":"Archivo de configuraci\u00f3n mosquitto.conf"},{"location":"iot/#cliente-mqtt-para-publicar-en-un-topic-publish","text":"En esta secci\u00f3n vamos a explicar c\u00f3mo podemos hacer uso de un cliente MQTT para publicar mensajes de prueba en el broker MQTT que acabamos de crear. Esta comprobaci\u00f3n deber\u00edamos realizarla antes de empezar a trabajar directamente con los sensores sobre el broker MQTT. Una vez que hayamos comprobado que podemos publicar y suscribirnos a los mensajes del broker con este cliente, ya podr\u00edamos realizar el siguiente paso para publicar mensajes con los sensores y recibirlos con el agente de Telegraf. Ejemplo: En este ejemplo vamos a publicar el valor 30 en el topic iescelia/aula22/co2 del broker MQTT test.mosquitto.org. Este broker es de prueba, por lo tanto, tendremos que cambiar este broker por la direcci\u00f3n IP de nuestro broker MQTT. docker run --init -it --rm efrecon/mqtt-client pub -h test.mosquitto.org -p 1883 -t \"iescelia/aula22/co2\" -m 30","title":"Cliente MQTT para publicar en un topic (publish)"},{"location":"iot/#cliente-mqtt-para-suscribirse-a-un-topic-subscribe","text":"Podemos hacer uso de un cliente MQTT para suscribirnos a los mensajes que se publican en un topic espec\u00edfico del broker MQTT. Esta comprobaci\u00f3n deber\u00edamos realizarla antes de empezar a trabajar directamente con los sensores sobre el broker MQTT. Una vez que hayamos comprobado que podemos publicar y suscribirnos a los mensajes del broker con este cliente, ya podr\u00edamos realizar el siguiente paso para publicar mensajes con los sensores y recibirlos con el agente de Telegraf. Ejemplo: En este ejemplo nos vamos a suscribir al topic iescelia/ del broker MQTT test.mosquitto.org. Con el wildcard estamos indicando que queremos suscribirnos a todos los topics que existan dentro de iescelia/, es decir, todos los mensajes que se publiquen en cada una de las aulas. Tenga en cuenta que tendr\u00e1 que cambiar el broker test.mosquitto.org por la direcci\u00f3n IP de nuestro broker MQTT. docker run --init -it --rm efrecon/mqtt-client sub -h test.mosquitto.org -t \"iescelia/#\"","title":"Cliente MQTT para suscribirse a un topic (subscribe)"},{"location":"iot/#telegraf","text":"Telegraf es un agente que nos permite recopilar y reportar m\u00e9tricas. Las m\u00e9tricas recogidas se pueden enviar a almacenes de datos, colas de mensajes o servicios como: InfluxDB, Graphite, OpenTSDB, Datadog, Kafka, MQTT, NSQ, entre otros.","title":"Telegraf"},{"location":"iot/#descripcion-del-servicio-en-docker-composeyml_1","text":"docker-compose.yml telegraf: image: telegraf volumes: - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf depends_on: - influxdb","title":"Descripci\u00f3n del servicio en docker-compose.yml"},{"location":"iot/#creacion-del-archivo-de-configuracion-telegrafconf","text":"En primer lugar tenemos que crear el archivo de configuraci\u00f3n telegraf.conf en nuestra m\u00e1quina local. Para crear el archivo de configuraci\u00f3n haremos uso del comando telegram config dentro del contenedor de Telegraf. docker run --rm telegraf telegraf config > telegraf.conf Una vez que hemos creado el archivo telegraf.conf lo movemos al directorio telegraf de nuestro proyecto. El contenido de nuestro directorio de trabajo debe tener los siguientes archivos. . \u251c\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 mosquitto \u2502 \u2514\u2500\u2500 mosquitto.conf \u2514\u2500\u2500 telegraf \u2514\u2500\u2500 telegraf.conf","title":"Creaci\u00f3n del archivo de configuraci\u00f3n telegraf.conf"},{"location":"iot/#configuracion-del-archivo-telegrafconf-para-suscribirnos-a-un-topic-mqtt","text":"Tendremos que buscar la secci\u00f3n inputs.mqtt_consumer dentro del archivo telegraf.conf y configurar los siguientes valores: servers topics data_format Existen m\u00e1s directivas de configuraci\u00f3n (qos, client_id, username, password, etc.), pero en este proyecto s\u00f3lo vamos a utilizar los valores que hemos indicado anteriormente. servers En esta directiva de configuraci\u00f3n indicamos la URL del broker MQTT al que queremos conectarnos. En nuestro caso pondremos el nombre del servicio mosquitto que es como lo hemos definido en nuestro archivo docker-compose.yml. topics En esta directiva indicamos los topics a los que queremos suscribirnos. En nuestro caso pondremos el topic iescelia/#. El car\u00e1cter # al final del topic indica que nos vamos a suscribir a cualquier topic que exista despu\u00e9s de la cadena iescelia/. data_format En esta directiva indicamos c\u00f3mo es el formato de los datos que vamos a recibir por MQTT. Telegraf contiene muchos plugins de prop\u00f3sito general que permiten parsear datos de entrada para convertirlos en el modelo de datos de m\u00e9tricas que utiliza InfluxDB.","title":"Configuraci\u00f3n del archivo telegraf.conf para suscribirnos a un topic MQTT"},{"location":"iot/#formato-value","text":"El formato value permite convertir valores simples en m\u00e9tricas de Telegraf. Es necesario indicar el tipo de dato al que queremos convertir el valor le\u00eddo, utilizando la opci\u00f3n de configuraci\u00f3n data_type. Los tipos de datos disponibles son: integer float o long string boolean","title":"Formato: Value"},{"location":"iot/#ejemplo-de-configuracion-de-la-seccion-inputsmqtt_consumer","text":"Si los mensajes que vamos a recibir por MQTT s\u00f3lo contienen valores num\u00e9ricos de tipo real que representan valores de temperatura, tendr\u00edamos que indicar: data_format = \"value\" y data_type = \"float\". Una posible configuraci\u00f3n para la secci\u00f3n inputs.mqtt_consumer del archivo telegraf.conf podr\u00eda ser la siguiente. [[inputs.mqtt_consumer]] servers = [\"tcp://mosquitto:1883\"] topics = [ \"iescelia/#\" ] data_format = \"value\" data_type = \"float\"","title":"Ejemplo de configuraci\u00f3n de la secci\u00f3n inputs.mqtt_consumer"},{"location":"iot/#formato-influxdb-line-protocol","text":"El formato influx no necesita ninguna configuraci\u00f3n adicional. Los valores que se reciben son parseados autom\u00e1ticamente a m\u00e9tricas de Telegraf. Si utilizamos data_format = \"influx\" los mensajes de entrada tienen que cumplir la sintaxis del protocolo InfluxDB line protocol. A continuaci\u00f3n se muestra un ejemplo de un mensaje con las sintaxis de InfluxDB line protocol. weather,location=us-midwest temperature=82 1465839830100400200 | -------------------- -------------- | | | | | | | | | +-----------+--------+-+---------+-+---------+ |measurement|,tag_set| |field_set| |timestamp| +-----------+--------+-+---------+-+---------+ El mensaje se compone de cuatro componentes: measurement: Indica la estructura de datos donde vamos a almacenar los valores en InfluxDB. tag_set: Es opcional. Son tags opcionales asociados al dato. Van detr\u00e1s de una coma despu\u00e9s del nombre de la measurement, sin espacios en blanco. field_set: Son los datos. Aparecen despu\u00e9s de un espacio en blanco despu\u00e9s de la meausrement. Podemos indicar varios datos separados por comas. timestamp: Es opcional. Es una marca de tiempo en Unix con precisi\u00f3n de nanosegundos.","title":"Formato: InfluxDB Line Protocol"},{"location":"iot/#ejemplos-de-mensajes-validos-con-la-sintaxis-del-protocolo-influxdb-line-protocol","text":"weather,location=us-midwest temperature=82 1465839830100400200 weather temperature=82 1465839830100400200 weather temperature=82 weather temperature=82,humidity=71 1465839830100400200 weather temperature=82,humidity=71","title":"Ejemplos de mensajes v\u00e1lidos con la sintaxis del protocolo InfluxDB line protocol"},{"location":"iot/#ejemplo-de-configuracion-de-la-seccion-inputsmqtt_consumer_1","text":"Una posible configuraci\u00f3n para la secci\u00f3n inputs.mqtt_consumer del archivo telegraf.conf podr\u00eda ser la siguiente. [[inputs.mqtt_consumer]] servers = [\"tcp://mosquitto:1883\"] topics = [ \"iescelia/#\" ] data_format = \"influx\"","title":"Ejemplo de configuraci\u00f3n de la secci\u00f3n inputs.mqtt_consumer"},{"location":"iot/#configuracion-del-archivo-telegrafconf-para-almacenar-los-datos-en-influxdb-outputsinfluxdb","text":"Tendremos que buscar la secci\u00f3n outputs.influxdb dentro del archivo telegraf.conf y configurar los siguientes valores: urls database skip_database_creation username password Existen m\u00e1s directivas de configuraci\u00f3n, pero en este proyecto s\u00f3lo vamos a utilizar los valores que hemos indicado anteriormente.","title":"Configuraci\u00f3n del archivo telegraf.conf para almacenar los datos en InfluxDB (outputs.influxdb)"},{"location":"iot/#urls","text":"En esta directiva de configuraci\u00f3n indicamos la URL de la instancia de InfluxDB donde vamos a almacenar los datos. En nuestro caso pondremos influxdb que es el nombre que le hemos puesto al servicio en el archivo docker-compose.yml","title":"urls"},{"location":"iot/#database","text":"En esta directiva indicamos el nombre de la base de datos donde vamos a almacenar las m\u00e9tricas.","title":"database"},{"location":"iot/#skip_database_creation","text":"Permite evitar la creaci\u00f3n de bases de datos en InfluxDB cuando est\u00e1 configurada como true. Se recomienda configurarla a true cuando estemos trabajando con usuarios que no tienen permisos para crear bases de datos o cuando la base de datos ya exista.","title":"skip_database_creation"},{"location":"iot/#username-y-password","text":"En esta directiva configuramos los par\u00e1metros de autenticaci\u00f3n para conectarnos a InfluxDB.","title":"username y password"},{"location":"iot/#ejemplo-de-configuracion-de-la-seccion-outputsmqtt_consumer","text":"Una posible configuraci\u00f3n de la secci\u00f3n outputs.influxdb podr\u00eda ser la siguiente: [[outputs.influxdb]] urls = [\"http://influxdb:8086\"] database = \"iescelia_db\" skip_database_creation = true username = \"root\" password = \"root\"","title":"Ejemplo de configuraci\u00f3n de la secci\u00f3n outputs.mqtt_consumer"},{"location":"iot/#influxdb","text":"InfluxDB es un sistema gestor de bases de datos dise\u00f1ado para almacenar bases de datos de series temporales (TSBD - Time Series Databases). Estas bases de datos se suelen utilizar en aplicaciones de monitorizaci\u00f3n, donde es necesario almacenar y analizar grandes cantidades de datos con marcas de tiempo, como pueden ser datos de uso de cpu, uso memoria, datos de sensores de IoT, etc.","title":"InfluxDB"},{"location":"iot/#descripcion-del-servicio-en-docker-composeyml_2","text":"docker-compose.yml influxdb: image: influxdb ports: - 8086:8086 volumes: - influxdb_data:/var/lib/influxdb environment: - INFLUXDB_DB=iescelia_db - INFLUXDB_ADMIN_USER=root - INFLUXDB_ADMIN_PASSWORD=root - INFLUXDB_HTTP_AUTH_ENABLED=true","title":"Descripci\u00f3n del servicio en docker-compose.yml"},{"location":"iot/#conectar-a-influxdb-desde-un-terminal","text":"Podemos conectarnos al contenedor de InfluxDB desde un terminal para comprobar si los datos que estamos recogiendo de los sensores se est\u00e1n insertando de forma correcta en la base de datos. En primer lugar necesitamos obtener el ID del contenedor que se est\u00e1 ejecutando con InfluxDB. Para obtener el listado de todos los contenedores que est\u00e1n en ejecuci\u00f3n podemos ejecutar el siguiente comando: docker ps Ahora s\u00f3lo tenemos que buscar el ID del contenedor con InfluxDB entre la lista de contenedores. En el ejemplo que se muestra a continuaci\u00f3n ser\u00eda el valor 27b06d552719. CONTAINER ID IMAGE COMMAND ... 27b06d552719 influxdb \"/entrypoint.sh infl\u2026\" ... ... Una vez que tenemos el ID del contenedor de InfluxDB, creamos un nuevo proceso con el comando /bin/bash dentro del contenedor para obtener un terminal que nos permita interactuar con el contenedor. docker exec -it 27b06d552719 /bin/bash Una vez que tenemos un terminal en el contenedor de InfluxDB, utilizamos el cliente influx para conectarnos al sistema gestor de bases de datos con el usuario y contrase\u00f1a que hemos creado en el archivo docker-compose.yml. influx -username root -password root Despu\u00e9s de autenticarnos, tendremos acceso al shell de InfluxDB donde podemos interaccionar con la base de datos con sentencias InfluxQL (Influx Query Language), que tienen una sintaxis muy similar a SQL.","title":"Conectar a InfluxDB desde un terminal"},{"location":"iot/#grafana","text":"Grafana es un servicio web que nos permite visualizar en un panel de control los datos almacenados en InfluxDB y otros sistemas gestores de bases de datos de series temporales.","title":"Grafana"},{"location":"iot/#descripcion-del-servicio-en-docker-composeyml_3","text":"docker-compose.yml grafana: image: grafana/grafana:7.4.0 ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana depends_on: - influxdb","title":"Descripci\u00f3n del servicio en docker-compose.yml"},{"location":"iot/#configuracion-de-un-data-source","text":"Grafana permite utilizar diferentes data sources, en nuestro proyecto utilizaremos InfluxDB pero tambi\u00e9n es posible utilizar AWS CloudWatch, Elasticsearch, MySQL o PostgreSQl entre otros.","title":"Configuraci\u00f3n de un data source"},{"location":"iot/#configuracion-de-forma-manual","text":"Antes de crear un dashboard es necesario crear un data source. S\u00f3lo los usuarios que tengan rol de administrador podr\u00e1n crear un data source. Para crear un data source debe seguir los siguientes pasos. Accede al menu lateral haciendo clien en el icono de Grafana del encabezado superior. Accede a la secci\u00f3n \"Data Sources\". A\u00f1ada un nuevo data source. Seleccione InfluxDB en el desplegable donde se indica el tipo de data source. Configure los par\u00e1metros url, database, user y password de su servicio InfluxDB. En la documentaci\u00f3n oficial puede encontrar m\u00e1s informaci\u00f3n sobre c\u00f3mo utilizar InfluxDB con Grafana.","title":"Configuraci\u00f3n de forma manual"},{"location":"iot/#configuracion-con-aprovisionamiento-automatico","text":"Es posible configurar Grafana para que utilize un archivo de configuraci\u00f3n de forma autom\u00e1tica para evitar tener que realizar la configuraci\u00f3n de forma manual. En nuestro proyecto, vamos a crear un archivo con el nombre datasource.yml dentro de la siguiente estructura de directorios. \u251c\u2500\u2500 grafana-provisioning \u2502 \u2514\u2500\u2500 datasources \u2502 \u2514\u2500\u2500 datasource.yml` El contenido del archivo datasource.yml ser\u00e1 el siguiente. apiVersion: 1 datasources: - name: InfluxDB type: influxdb access: proxy database: iescelia_db user: root password: root url: http://influxdb:8086 isDefault: true editable: true Para que el aprovisionamiento se realice forma correcta, tenemos que definir un nuevo volumen en el servicio de Grafana en el archivo docker-compose.yml. docker-compose.yml grafana: image: grafana/grafana:7.4.0 ports: - 3000:3000 volumes: - grafana_data:/var/lib/grafana - ./grafana-provisioning/:/etc/grafana/provisioning depends_on: - influxdb","title":"Configuraci\u00f3n con aprovisionamiento autom\u00e1tico"},{"location":"iot/#configuracion-de-un-dashboard","text":"","title":"Configuraci\u00f3n de un dashboard"},{"location":"iot/#configuracion-con-aprovisionamiento-automatico_1","text":"Es posible configurar Grafana para que utilize un archivo de configuraci\u00f3n de forma autom\u00e1tica para evitar tener que realizar la configuraci\u00f3n del dashboard de forma manual. En nuestro proyecto, vamos a crear los archivos dashboard.yml y CO2Dashboard.json dentro de la siguiente estructura de directorios. \u251c\u2500\u2500 grafana-provisioning \u2502 \u251c\u2500\u2500 dashboards \u2502 \u2502 \u251c\u2500\u2500 CO2Dashboard.json \u2502 \u2502 \u2514\u2500\u2500 dashboard.yml \u2502 \u2514\u2500\u2500 datasources \u2502 \u2514\u2500\u2500 datasource.yml El contenido del archivo dashboard.yml ser\u00e1 el siguiente. apiVersion: 1 providers: - name: InfluxDB folder: '' type: file disableDeletion: false editable: true options: path: /etc/grafana/provisioning/dashboards Un dashboard de Grafana se representa por un objeto JSON, que almacena todos los metadatos del dashboard. Estos metadatos incluyen propiedades de los paneles, variables, etc. El archivo CO2Dashboard.json contiene los metadatos del los paneles que hemos creado para el dashboard de este proyecto. A continuaci\u00f3n se muestra una imagen del dashboard almacenado en el archivo CO2Dashboard.json.","title":"Configuraci\u00f3n con aprovisionamiento autom\u00e1tico"},{"location":"jekyll/","text":"Pr\u00e1ctica: Creaci\u00f3n de blogs con Jekyll y GitHub Pages Jekyll es un generador de sitios web est\u00e1ticos que nos permite crear de forma sencilla blogs, sitios webs personales o webs para proyectos. Los sitios webs generados con Jekyll no usan una base de datos, el contenido del sitio web est\u00e1 escrito en archivos de texto plano en formato Markdown (o Textile) y plantillas Liquid. Jekyll es el motor de GitHub Pages, un servicio que ofrece GitHub a sus usuarios para que puedan publicar sitios webs est\u00e1ticos alojados en los repositorios que tienen en GitHub. Creaci\u00f3n de un contenedor Docker con Jekyll Si buscamos la imagen oficial de Jekyll en Docker Hub encontraremos el repositorio oficicial en GitHub. En esta pr\u00e1ctica utilizaresmos la imagen por defecto jekyll/jekyll. Repositorio de GitHub Vamos a crear un repositorio en GitHub con nuestro nombre seguido del dominio github.io Con el repositorio creado, lo clonamos en la m\u00e1quina con la que estamos trabajando. Cuando se haya clonado entramos y lanzamos el contenedor de Jekyll que nos crear\u00e1 la infraestructura de nuestro blog. docker run -it --rm -v \"$PWD:/srv/jekyll\" jekyll/jekyll jekyll new blog Se nos crear\u00e1 un nuevo directorio llamado blog, debemos mover todo el contenido de ese directorio a la ra\u00edz del directorio clonado. Antes de subir nuestra p\u00e1gina, aprenderemos a manejar los posts. Con todos los pasos anteriores hechos, a la hora de crear/editar posts tenemos que hacer lo siguiente: En la carpeta _posts se almacenan todos los posts de nuestro sitio, si lo desplegamos encontraremos un archivo de ejemplo bajo el nombre de Fecha-de-creacion-welcome-to-jekyll.markdown Los posts se escriben en lenguaje markdown, tienen una estructura que siempre se debe respetar y que podemos encontrar en ese post de ejemplo. Dentro del archivo encontraremos las secciones correspondientes a el t\u00edtulo que le podemos poner, fecha de redacci\u00f3n, y categor\u00eda. A continuaci\u00f3n podemos empezar a redactar el contenido de nuestro post utilizando el lenguaje de markdown Publicar el blog Para subir nuestro blog a GitHub y que est\u00e9 disponible podremos hacer lo siguiente: git add --all git commit -m \"Comentario para el commit\" git push A continuaci\u00f3n, cuando todo est\u00e9 listo podremos acceder a nuestro blog a trav\u00e9s del nombre de nuestro repositorio.","title":"Practica Jekyll"},{"location":"jekyll/#practica-creacion-de-blogs-con-jekyll-y-github-pages","text":"Jekyll es un generador de sitios web est\u00e1ticos que nos permite crear de forma sencilla blogs, sitios webs personales o webs para proyectos. Los sitios webs generados con Jekyll no usan una base de datos, el contenido del sitio web est\u00e1 escrito en archivos de texto plano en formato Markdown (o Textile) y plantillas Liquid. Jekyll es el motor de GitHub Pages, un servicio que ofrece GitHub a sus usuarios para que puedan publicar sitios webs est\u00e1ticos alojados en los repositorios que tienen en GitHub.","title":"Pr\u00e1ctica: Creaci\u00f3n de blogs con Jekyll y GitHub Pages"},{"location":"jekyll/#creacion-de-un-contenedor-docker-con-jekyll","text":"Si buscamos la imagen oficial de Jekyll en Docker Hub encontraremos el repositorio oficicial en GitHub. En esta pr\u00e1ctica utilizaresmos la imagen por defecto jekyll/jekyll.","title":"Creaci\u00f3n de un contenedor Docker con Jekyll"},{"location":"jekyll/#repositorio-de-github","text":"Vamos a crear un repositorio en GitHub con nuestro nombre seguido del dominio github.io Con el repositorio creado, lo clonamos en la m\u00e1quina con la que estamos trabajando. Cuando se haya clonado entramos y lanzamos el contenedor de Jekyll que nos crear\u00e1 la infraestructura de nuestro blog. docker run -it --rm -v \"$PWD:/srv/jekyll\" jekyll/jekyll jekyll new blog Se nos crear\u00e1 un nuevo directorio llamado blog, debemos mover todo el contenido de ese directorio a la ra\u00edz del directorio clonado. Antes de subir nuestra p\u00e1gina, aprenderemos a manejar los posts. Con todos los pasos anteriores hechos, a la hora de crear/editar posts tenemos que hacer lo siguiente: En la carpeta _posts se almacenan todos los posts de nuestro sitio, si lo desplegamos encontraremos un archivo de ejemplo bajo el nombre de Fecha-de-creacion-welcome-to-jekyll.markdown Los posts se escriben en lenguaje markdown, tienen una estructura que siempre se debe respetar y que podemos encontrar en ese post de ejemplo. Dentro del archivo encontraremos las secciones correspondientes a el t\u00edtulo que le podemos poner, fecha de redacci\u00f3n, y categor\u00eda. A continuaci\u00f3n podemos empezar a redactar el contenido de nuestro post utilizando el lenguaje de markdown","title":"Repositorio de GitHub"},{"location":"jekyll/#publicar-el-blog","text":"Para subir nuestro blog a GitHub y que est\u00e9 disponible podremos hacer lo siguiente: git add --all git commit -m \"Comentario para el commit\" git push A continuaci\u00f3n, cuando todo est\u00e9 listo podremos acceder a nuestro blog a trav\u00e9s del nombre de nuestro repositorio.","title":"Publicar el blog"}]}